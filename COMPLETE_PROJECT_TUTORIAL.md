# ğŸ“ COMPLETE NEPHRO-AI PROJECT TUTORIAL

## Teaching You Like the World's Best Teacher

Welcome! I'm going to teach you this entire Nephro-AI project from the ground up, explaining every concept, component, and how they work together.

---

## ğŸ“š TABLE OF CONTENTS

1. [What is Nephro-AI?](#1-what-is-nephro-ai)
2. [The Big Picture - How It All Works](#2-the-big-picture)
3. [Core Concepts Explained](#3-core-concepts-explained)
4. [Project Architecture](#4-project-architecture)
5. [The Data Pipeline](#5-the-data-pipeline)
6. [Vector Embeddings Explained](#6-vector-embeddings-explained)
7. [The Vector Database](#7-the-vector-database)
8. [Query System & RAG](#8-query-system--rag)
9. [Code Walkthrough](#9-code-walkthrough)
10. [How to Use It](#10-how-to-use-it)
11. [Advanced Topics](#11-advanced-topics)
12. [Real-World Applications](#12-real-world-applications)

---

## 1. WHAT IS NEPHRO-AI?

### The Simple Explanation

Imagine you have a **super-smart medical librarian** who has read hundreds of medical documents about kidney disease. When you ask a question, this librarian instantly finds the most relevant information and gives you accurate answers.

**Nephro-AI is that librarian**, but powered by AI.

### The Technical Explanation

Nephro-AI is an **AI-powered medical knowledge retrieval system** that:

- Processes medical documents about Chronic Kidney Disease (CKD)
- Converts them into "semantic vectors" (mathematical representations)
- Stores them in a searchable database
- Allows natural language queries to find relevant information
- Powers AI chatbots through Retrieval-Augmented Generation (RAG)

### Why Is This Important?

**Problem:** Medical professionals and patients need quick access to accurate, evidence-based kidney care information.

**Traditional Solution:**

- Search through hundreds of PDF documents manually
- Use keyword search (misses related concepts)
- Time-consuming and error-prone

**Nephro-AI Solution:**

- Instant semantic search (understands meaning, not just keywords)
- Finds relevant information even with different wording
- Provides context for AI-powered medical assistants

---

## 2. THE BIG PICTURE - HOW IT ALL WORKS

### The Journey of Information

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PDF Documents  â”‚  â† Medical guidelines, research papers
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Text Extractor â”‚  â† Reads and cleans text
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Smart Chunker  â”‚  â† Breaks into logical pieces
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Metadata Adder â”‚  â† Tags with medical entities
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Quality Filter  â”‚  â† Removes low-quality chunks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding Model â”‚  â† Converts text to vectors (1536 numbers)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector DB      â”‚  â† Stores in ChromaDB
â”‚  (ChromaDB)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query System   â”‚  â† You ask questions here!
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Real-World Example

**Input:** PDF of "KDIGO 2024 Clinical Practice Guideline for CKD" (199 pages)

**Process:**

1. Extract text â†’ 936,183 characters
2. Clean and chunk â†’ 243 chunks
3. Filter quality â†’ 197 high-quality chunks
4. Add metadata â†’ Tagged with CKD, GFR, diabetes, etc.
5. Generate embeddings â†’ 197 Ã— 1536-dimensional vectors
6. Store in ChromaDB â†’ Searchable database

**Output:** You can now ask "What dietary changes help CKD patients?" and get instant, relevant answers!

---

## 3. CORE CONCEPTS EXPLAINED

### A. What is Chronic Kidney Disease (CKD)?

**Simple:** Your kidneys filter waste from blood. CKD means they're not working as well as they should.

**Technical:** Progressive loss of kidney function measured by GFR (Glomerular Filtration Rate), staged from 1 (mild) to 5 (kidney failure).

### B. What are Embeddings?

**Simple Analogy:** Think of words as locations on a map. Similar words are close together. "Kidney" and "renal" are neighbors. "Kidney" and "bicycle" are far apart.

**Technical:** Mathematical representations of text where semantic meaning is encoded in high-dimensional space (1536 dimensions). Similar concepts have similar vector representations.

**Example:**

```
Text: "chronic kidney disease"
â†“ OpenAI text-embedding-3-small
â†“
Vector: [0.006, 0.004, 0.0002, 0.042, 0.030, ..., 0.015]
        â†‘ 1536 numbers total
```

### C. What is a Vector Database?

**Simple:** A special type of database that stores these "embedding vectors" and can quickly find similar ones.

**Technical:** ChromaDB uses HNSW (Hierarchical Navigable Small World) algorithm for approximate nearest neighbor search. It finds similar vectors using cosine similarity in ~100ms.

**Why Not Regular Database?**

- Regular DB: Find exact matches ("SELECT \* WHERE text = 'kidney disease'")
- Vector DB: Find semantic matches ("Find documents about kidney problems") â† understands synonyms, related concepts

### D. What is RAG (Retrieval-Augmented Generation)?

**The Problem:** Large Language Models (like ChatGPT) don't know specific medical guidelines. They hallucinate.

**The Solution:** RAG = Retrieve relevant documents + Augment LLM prompt + Generate accurate answer

**Example:**

```
User: "What are CKD treatment options?"
â†“
1. RETRIEVE: Query vector DB â†’ Get relevant chunks about CKD treatment
2. AUGMENT: Add chunks to prompt â†’ "Based on KDIGO guidelines: [chunks]..."
3. GENERATE: LLM reads context â†’ Generates accurate, evidence-based answer
```

### E. What is Semantic Search?

**Keyword Search (Old):**

```
Query: "kidney failure"
Matches: Documents with exact words "kidney" AND "failure"
Misses: Documents saying "renal insufficiency" or "ESRD"
```

**Semantic Search (New):**

```
Query: "kidney failure"
Matches: Documents about:
  - "kidney failure" âœ“
  - "renal failure" âœ“
  - "end-stage renal disease" âœ“
  - "ESRD" âœ“
  - "dialysis" âœ“ (related concept)
```

---

## 4. PROJECT ARCHITECTURE

### File Structure Explained

```
Nephro-AI/
â”‚
â”œâ”€â”€ ğŸ“„ config.py                    â† BRAIN: Central configuration
â”‚   â”œâ”€â”€ Paths to all directories
â”‚   â”œâ”€â”€ Embedding model settings
â”‚   â”œâ”€â”€ Medical entities list
â”‚   â””â”€â”€ API credentials
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt             â† Dependencies (libraries needed)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                        â† DATA STORAGE
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                     â† Original PDF files
â”‚   â”‚   â””â”€â”€ medical_knowledge/
â”‚   â”‚       â”œâ”€â”€ diseases/
â”‚   â”‚       â”œâ”€â”€ treatments/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ processed/               â† Extracted and chunked text
â”‚   â”‚   â”œâ”€â”€ *_chunks.json          â† Chunk data
â”‚   â”‚   â””â”€â”€ *_metadata.json        â† Metadata
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ vectordb_ready/          â† Filtered, ready for embeddings
â”‚       â””â”€â”€ documents/
â”‚           â””â”€â”€ *_vectordb_ready.json
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                     â† THE WORKERS
â”‚   â”‚
â”‚   â”œâ”€â”€ pdf_extractor.py           â† STEP 1: Extract text from PDFs
â”‚   â”œâ”€â”€ analyze_chunks.py          â† Analysis & statistics
â”‚   â”œâ”€â”€ prepare_vectordb.py        â† STEP 2: Quality filtering
â”‚   â”œâ”€â”€ openai_embeddings.py       â† NEW: OpenAI API wrapper
â”‚   â”œâ”€â”€ build_vectordb.py          â† STEP 3: Build vector database
â”‚   â”œâ”€â”€ query_vectordb.py          â† STEP 4: Query interface
â”‚   â”œâ”€â”€ rag_example.py             â† RAG demonstration
â”‚   â””â”€â”€ quick_start.py             â† Quick start guide
â”‚
â””â”€â”€ ğŸ“‚ vectordb/                    â† THE DATABASE
    â””â”€â”€ chroma_db/                  â† ChromaDB storage
        â”œâ”€â”€ chroma.sqlite3          â† Metadata database
        â””â”€â”€ [embedding data]        â† Vector embeddings
```

### Key Components

#### 1. **config.py** - The Control Center

- Defines all paths, settings, and constants
- Medical entities to detect (CKD, GFR, diabetes, etc.)
- Content type classifications
- API credentials for OpenAI

#### 2. **Data Pipeline Scripts**

- **pdf_extractor.py**: PDF â†’ Text chunks + Metadata
- **prepare_vectordb.py**: Filter quality chunks
- **build_vectordb.py**: Generate embeddings + Store in DB

#### 3. **Query & Application Scripts**

- **query_vectordb.py**: Search interface
- **rag_example.py**: Show how to use with LLMs
- **quick_start.py**: Demo and exploration

---

## 5. THE DATA PIPELINE

### Step-by-Step Process

#### STEP 1: PDF Extraction (`pdf_extractor.py`)

**What it does:**

1. Reads PDF files using pdfplumber (primary) or PyPDF2 (fallback)
2. Cleans text (removes extra spaces, fixes encoding)
3. Chunks text intelligently (500 words per chunk, 50-word overlap)
4. Adds metadata to each chunk

**Chunking Strategy:**

```
Original Text: "Chronic kidney disease is... [5000 words]"

Chunk 1: [Words 1-500]     â† First 500 words
Chunk 2: [Words 451-950]   â† 50-word overlap with Chunk 1
Chunk 3: [Words 901-1400]  â† 50-word overlap with Chunk 2
...
```

**Why overlap?** Prevents losing context at chunk boundaries.

**Output:** `*_chunks.json` and `*_metadata.json`

#### STEP 2: Quality Filtering (`prepare_vectordb.py`)

**What it does:**

1. Filters out low-quality chunks:
   - Too short (< 50 words)
   - Too long (> 600 words)
   - Not enough medical keywords (< 2)
   - Mostly references/citations
2. Formats for ChromaDB
3. Generates sample queries

**Quality Metrics:**

```python
âœ“ Word count: 50-600
âœ“ Medical keywords: â‰¥ 2
âœ“ Not just references
âœ“ Contains substantive content
```

**Result:** 197 high-quality chunks (81% retention rate)

**Output:** `*_vectordb_ready.json`

#### STEP 3: Embedding Generation (`build_vectordb.py` + `openai_embeddings.py`)

**What it does:**

1. Reads vectordb_ready JSON files
2. Calls OpenAI API to generate embeddings
3. Stores in ChromaDB

**Embedding Process:**

```
Text: "Chronic kidney disease (CKD) is defined as..."

â†“ OpenAI API Call

POST https://openrouter.ai/api/v1/embeddings
{
  "model": "openai/text-embedding-3-small",
  "input": "Chronic kidney disease (CKD) is defined as..."
}

â†“ Response

{
  "data": [{
    "embedding": [0.006, 0.004, ..., 0.015],  â† 1536 numbers
    "index": 0
  }]
}

â†“ Store in ChromaDB
```

**Output:** ChromaDB database in `vectordb/chroma_db/`

### Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   INPUT: PDF Files                   â”‚
â”‚         KDIGO 2024 CKD Guideline (199 pages)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            pdf_extractor.py                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Extract Text (pdfplumber/PyPDF2)             â”‚   â”‚
â”‚  â”‚ â”œâ”€ Page 1: "Chronic kidney disease..."       â”‚   â”‚
â”‚  â”‚ â”œâ”€ Page 2: "GFR measurement is..."           â”‚   â”‚
â”‚  â”‚ â””â”€ Page 199: "...treatment options"          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Clean Text                                    â”‚   â”‚
â”‚  â”‚ â”œâ”€ Fix encoding issues                       â”‚   â”‚
â”‚  â”‚ â”œâ”€ Remove extra whitespace                   â”‚   â”‚
â”‚  â”‚ â””â”€ Normalize medical terms                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Chunk Text (500 words, 50 overlap)           â”‚   â”‚
â”‚  â”‚ Chunk 0: "Chronic kidney disease..."         â”‚   â”‚
â”‚  â”‚ Chunk 1: "...GFR measurement..."             â”‚   â”‚
â”‚  â”‚ Chunk 242: "...treatment outcomes"           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Add Metadata                                  â”‚   â”‚
â”‚  â”‚ â”œâ”€ Source: "KDIGO-2024-CKD-Guideline.pdf"    â”‚   â”‚
â”‚  â”‚ â”œâ”€ Content type: "recommendation"            â”‚   â”‚
â”‚  â”‚ â”œâ”€ Medical entities: "CKD, GFR, diabetes"    â”‚   â”‚
â”‚  â”‚ â””â”€ Word count: 485                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          OUTPUT: 243 chunks
     data/processed/*_chunks.json
                  â”‚
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            prepare_vectordb.py                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Quality Filtering                             â”‚   â”‚
â”‚  â”‚ â”œâ”€ Remove too short (< 50 words)             â”‚   â”‚
â”‚  â”‚ â”œâ”€ Remove too long (> 600 words)             â”‚   â”‚
â”‚  â”‚ â”œâ”€ Remove low medical content (< 2 keywords) â”‚   â”‚
â”‚  â”‚ â””â”€ Remove reference-only chunks              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                                    â”‚
â”‚         197 chunks pass (81%)                       â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Format for ChromaDB                           â”‚   â”‚
â”‚  â”‚ {                                             â”‚   â”‚
â”‚  â”‚   "documents": [texts...],                    â”‚   â”‚
â”‚  â”‚   "metadatas": [metadata...],                 â”‚   â”‚
â”‚  â”‚   "ids": ["kdigo_2024_0", ...]               â”‚   â”‚
â”‚  â”‚ }                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          OUTPUT: 197 chunks
  data/vectordb_ready/*_vectordb_ready.json
                  â”‚
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     build_vectordb.py + openai_embeddings.py        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Load vectordb_ready documents                 â”‚   â”‚
â”‚  â”‚ 197 chunks Ã— 485 words avg                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Generate Embeddings (OpenAI API)              â”‚   â”‚
â”‚  â”‚                                               â”‚   â”‚
â”‚  â”‚ For each chunk:                               â”‚   â”‚
â”‚  â”‚   POST openrouter.ai/api/v1/embeddings       â”‚   â”‚
â”‚  â”‚   {                                           â”‚   â”‚
â”‚  â”‚     "model": "openai/text-embedding-3-small", â”‚   â”‚
â”‚  â”‚     "input": "Chronic kidney disease..."      â”‚   â”‚
â”‚  â”‚   }                                           â”‚   â”‚
â”‚  â”‚   â†“                                           â”‚   â”‚
â”‚  â”‚   Response: [0.006, 0.004, ..., 0.015]       â”‚   â”‚
â”‚  â”‚              â†‘ 1536 dimensions                â”‚   â”‚
â”‚  â”‚                                               â”‚   â”‚
â”‚  â”‚ Batch size: 100 chunks per API call          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Store in ChromaDB                             â”‚   â”‚
â”‚  â”‚                                               â”‚   â”‚
â”‚  â”‚ collection.add(                               â”‚   â”‚
â”‚  â”‚   documents=[texts],                          â”‚   â”‚
â”‚  â”‚   embeddings=[[1536 floats], ...],           â”‚   â”‚
â”‚  â”‚   metadatas=[metadata],                       â”‚   â”‚
â”‚  â”‚   ids=["kdigo_2024_0", ...]                  â”‚   â”‚
â”‚  â”‚ )                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               OUTPUT: Vector Database                â”‚
â”‚                                                      â”‚
â”‚             vectordb/chroma_db/                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Collection: nephro_ai_medical_kb           â”‚    â”‚
â”‚   â”‚ Documents: 197                             â”‚    â”‚
â”‚   â”‚ Dimension: 1536                            â”‚    â”‚
â”‚   â”‚ Model: openai/text-embedding-3-small       â”‚    â”‚
â”‚   â”‚                                            â”‚    â”‚
â”‚   â”‚ [Document 0] â†â†’ [Embedding Vector 0]       â”‚    â”‚
â”‚   â”‚ [Document 1] â†â†’ [Embedding Vector 1]       â”‚    â”‚
â”‚   â”‚ ...                                        â”‚    â”‚
â”‚   â”‚ [Document 196] â†â†’ [Embedding Vector 196]   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                      â”‚
â”‚   READY FOR QUERIES! âœ“                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. VECTOR EMBEDDINGS EXPLAINED

### The Magic of Embeddings

**The Problem:** Computers can't understand text. They need numbers.

**The Solution:** Convert text to numbers that capture meaning.

### How Do Embeddings Work?

#### Simple Analogy: Color Space

Imagine describing colors with 3 numbers:

```
Red:   [255, 0, 0]
Blue:  [0, 0, 255]
Purple: [128, 0, 128]  â† Mix of red and blue
```

Similar colors have similar numbers. Purple is between red and blue.

#### Text Embeddings: Same Idea, But 1536 Dimensions

```
"kidney":     [0.12, 0.34, ..., 0.67]  â† 1536 numbers
"renal":      [0.13, 0.33, ..., 0.68]  â† Very similar!
"bicycle":    [0.91, 0.02, ..., 0.11]  â† Very different
```

### Why 1536 Dimensions?

More dimensions = More nuanced meaning.

**3D example:**

- X-axis: Medical vs non-medical
- Y-axis: Kidney vs heart vs lung
- Z-axis: Treatment vs diagnosis

**1536D:**

- Dimension 1: Medical specialty
- Dimension 2: Body system
- Dimension 3: Severity
- ...
- Dimension 1536: Contextual nuance

### Measuring Similarity

**Cosine Similarity:**

```
similarity = cos(angle between vectors)

High similarity (close to 1):  Vectors point same direction
Low similarity (close to 0):   Vectors point different directions
```

**Example:**

```python
embedding_A = [0.5, 0.8, 0.3]  # "chronic kidney disease"
embedding_B = [0.6, 0.7, 0.4]  # "CKD"

similarity = cosine_similarity(A, B) = 0.97  â† Very similar!
```

### Why OpenAI text-embedding-3-small?

**Before: all-MiniLM-L6-v2 (local)**

- Dimension: 384
- Model size: 90MB
- Quality: Good
- Speed: Fast (local)
- Cost: Free

**After: openai/text-embedding-3-small (API)**

- Dimension: 1536 (4Ã— more nuanced!)
- Model size: 0 (cloud-hosted)
- Quality: Excellent (state-of-the-art)
- Speed: Fast (100ms API)
- Cost: $0.02 per 1M tokens (~$0.003 per rebuild)

**Why the upgrade?**

1. **Better medical understanding:** Trained on massive medical corpus
2. **Higher accuracy:** Finds more relevant results
3. **Latest technology:** Continuously improved by OpenAI
4. **No local resources:** No GPU/CPU needed

---

## 7. THE VECTOR DATABASE

### What is ChromaDB?

**Simple:** A specialized database for storing and searching embeddings.

**Technical:** Open-source embedding database with:

- HNSW indexing for fast approximate nearest neighbor search
- SQLite backend for metadata
- Python API for easy integration
- Sub-100ms query times

### How ChromaDB Organizes Data

```
Collection: nephro_ai_medical_kb
â”‚
â”œâ”€â”€ Document 0
â”‚   â”œâ”€â”€ Text: "Chronic kidney disease (CKD) is..."
â”‚   â”œâ”€â”€ Embedding: [0.006, 0.004, ..., 0.015]
â”‚   â”œâ”€â”€ Metadata: {
â”‚   â”‚     source: "KDIGO-2024-CKD-Guideline.pdf",
â”‚   â”‚     content_type: "recommendation",
â”‚   â”‚     medical_entities: "CKD,GFR,diabetes",
â”‚   â”‚     word_count: 485
â”‚   â”‚   }
â”‚   â””â”€â”€ ID: "kdigo_2024_0"
â”‚
â”œâ”€â”€ Document 1
â”‚   â”œâ”€â”€ Text: "GFR measurement..."
â”‚   â”œâ”€â”€ Embedding: [0.023, 0.011, ..., 0.008]
â”‚   â”œâ”€â”€ Metadata: {...}
â”‚   â””â”€â”€ ID: "kdigo_2024_1"
â”‚
â””â”€â”€ ... (197 total documents)
```

### Query Process

When you search, ChromaDB:

1. **Converts your query to embedding:**

   ```python
   query = "What is chronic kidney disease?"
   query_embedding = openai_embed(query)
   # â†’ [0.007, 0.005, ..., 0.014]
   ```

2. **Finds similar embeddings using HNSW:**

   ```
   HNSW index â†’ Navigate graph â†’ Find nearest neighbors
   ```

3. **Calculates similarities:**

   ```python
   for doc in documents:
       similarity = cosine_similarity(query_embedding, doc.embedding)
   ```

4. **Ranks and returns top results:**

   ```python
   results = sort_by_similarity(documents)[:5]
   ```

5. **Applies metadata filters (optional):**
   ```python
   results = filter(results, where={"content_type": "recommendation"})
   ```

### Why So Fast?

**Naive approach (slow):**

- Compare query to ALL 197 documents
- Time: O(n) = linear

**HNSW approach (fast):**

- Navigate hierarchical graph
- Only check ~log(n) candidates
- Time: O(log n) = logarithmic

**Result:** Sub-100ms even with millions of documents!

---

## 8. QUERY SYSTEM & RAG

### Query Interface (`query_vectordb.py`)

#### Simple Query

```powershell
python scripts/query_vectordb.py "What is CKD?"
```

**What happens:**

1. Load ChromaDB collection
2. Convert query to embedding via OpenAI API
3. Search for 5 most similar documents
4. Display results with similarity scores

#### Interactive Mode

```powershell
python scripts/query_vectordb.py
```

Then type queries:

```
ğŸ” Query: What are CKD treatment options?

ğŸ“Š Result 1 (Similarity: 0.892)
   Type: recommendation
   Entities: CKD,treatment,therapy

   "Treatment options for CKD include lifestyle modifications..."

---

ğŸ” Query: filter:recommendation diabetes
ğŸ“Š Filtered results: Only recommendations about diabetes

ğŸ” Query: top10 kidney failure symptoms
ğŸ“Š Showing top 10 results instead of default 5

ğŸ” Query: stats
ğŸ“Š Database Statistics:
    Total documents: 197
    Content types: recommendation (128), reference (46), ...

ğŸ” Query: quit
```

### Advanced Querying

#### Metadata Filters

```python
# Only recommendations
results = collection.query(
    query_texts=["diabetes management"],
    where={"content_type": "recommendation"}
)

# Multiple filters
results = collection.query(
    query_texts=["treatment options"],
    where={
        "content_type": "recommendation",
        "has_diabetes": True
    }
)
```

#### Custom Result Count

```python
# Get top 10 results
results = collection.query(
    query_texts=["CKD stages"],
    n_results=10
)
```

### RAG (Retrieval-Augmented Generation)

#### The RAG Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Question                               â”‚
â”‚ "What dietary changes help CKD patients?"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: RETRIEVE                                 â”‚
â”‚                                                  â”‚
â”‚ Query vector database                            â”‚
â”‚ â†“                                                â”‚
â”‚ Top 5 relevant chunks:                           â”‚
â”‚ 1. "Dietary protein restriction..."             â”‚
â”‚ 2. "Sodium intake should be limited..."         â”‚
â”‚ 3. "Potassium management in CKD..."             â”‚
â”‚ 4. "Phosphorus restriction guidelines..."       â”‚
â”‚ 5. "Fluid management recommendations..."         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: AUGMENT                                  â”‚
â”‚                                                  â”‚
â”‚ Build context-enriched prompt:                   â”‚
â”‚                                                  â”‚
â”‚ System: "You are a medical AI assistant."       â”‚
â”‚                                                  â”‚
â”‚ Context: "Based on KDIGO 2024 guidelines:       â”‚
â”‚ [Chunk 1: Dietary protein restriction...]       â”‚
â”‚ [Chunk 2: Sodium intake should be...]           â”‚
â”‚ [Chunk 3: Potassium management...]              â”‚
â”‚ [Chunk 4: Phosphorus restriction...]            â”‚
â”‚ [Chunk 5: Fluid management...]"                 â”‚
â”‚                                                  â”‚
â”‚ Question: "What dietary changes help CKD?"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: GENERATE                                 â”‚
â”‚                                                  â”‚
â”‚ Send to LLM (GPT-4, Claude, Gemini, etc.)       â”‚
â”‚ â†“                                                â”‚
â”‚ LLM reads context + generates answer:            â”‚
â”‚                                                  â”‚
â”‚ "Based on KDIGO 2024 guidelines, CKD patients   â”‚
â”‚ should consider these dietary changes:          â”‚
â”‚                                                  â”‚
â”‚ 1. Protein: Moderate restriction (0.8 g/kg/day) â”‚
â”‚ 2. Sodium: Limit to < 2g/day                    â”‚
â”‚ 3. Potassium: Monitor and adjust based on labs  â”‚
â”‚ 4. Phosphorus: Restrict to 800-1000 mg/day      â”‚
â”‚ 5. Fluids: Adjust based on urine output         â”‚
â”‚                                                  â”‚
â”‚ These recommendations help slow CKD progression  â”‚
â”‚ and manage complications."                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final Answer (Accurate + Evidence-Based!)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Code Example

```python
import chromadb
import openai

# 1. RETRIEVE
def retrieve_context(question):
    client = chromadb.PersistentClient(path="vectordb/chroma_db")
    collection = client.get_collection("nephro_ai_medical_kb")

    results = collection.query(
        query_texts=[question],
        n_results=5
    )

    # Combine retrieved chunks
    context = "\n\n".join(results['documents'][0])
    return context

# 2. AUGMENT
def build_prompt(question, context):
    prompt = f"""You are a medical AI assistant specializing in kidney care.

Based on the following medical guidelines:

{context}

Please answer this question: {question}

Provide an accurate, evidence-based answer."""

    return prompt

# 3. GENERATE
def generate_answer(prompt):
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "You are a medical AI assistant."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )

    return response.choices[0].message.content

# Complete RAG Pipeline
question = "What dietary changes help CKD patients?"
context = retrieve_context(question)
prompt = build_prompt(question, context)
answer = generate_answer(prompt)

print(answer)
```

---

## 9. CODE WALKTHROUGH

### A. Configuration (`config.py`)

```python
# Project structure
PROJECT_ROOT = Path(__file__).parent
DATA_DIR = PROJECT_ROOT / "data"
VECTORDB_DIR = PROJECT_ROOT / "vectordb"
CHROMA_DB_PATH = VECTORDB_DIR / "chroma_db"

# Embedding settings
EMBEDDING_MODEL = "openai/text-embedding-3-small"
EMBEDDING_DIMENSION = 1536

# OpenRouter API (for OpenAI embeddings)
OPENROUTER_API_KEY = "sk-or-v1-..."
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/embeddings"

# Medical entities to detect
MEDICAL_ENTITIES = [
    "CKD", "chronic kidney disease",
    "GFR", "glomerular filtration rate",
    "albuminuria", "proteinuria",
    "dialysis", "hemodialysis",
    # ... 100+ medical terms
]

# Content type classification
CONTENT_TYPE_KEYWORDS = {
    "recommendation": ["recommend", "should", "suggest"],
    "evidence": ["study", "research", "trial"],
    "definition": ["is defined as", "refers to"],
    # ...
}
```

**Why centralized config?**

- Single source of truth
- Easy to modify settings
- Consistent across all scripts

### B. OpenAI Embeddings (`openai_embeddings.py`)

```python
class OpenAIEmbeddings:
    """Generate embeddings using OpenAI's API via OpenRouter"""

    def __init__(self, api_key, model="openai/text-embedding-3-small"):
        self.api_key = api_key
        self.model = model
        self.api_url = "https://openrouter.ai/api/v1/embeddings"

    def encode(self, texts, batch_size=100):
        """Encode texts into embeddings"""
        all_embeddings = []

        # Process in batches
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]

            # API call
            response = requests.post(
                self.api_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "input": batch,
                    "encoding_format": "float"
                }
            )

            # Extract embeddings
            data = response.json()
            embeddings = [item['embedding'] for item in data['data']]
            all_embeddings.extend(embeddings)

        return all_embeddings
```

**Key features:**

- Batch processing (100 texts per API call)
- Error handling with retries
- Progress tracking
- Compatible with SentenceTransformer interface

### C. Vector Database Builder (`build_vectordb.py`)

```python
class VectorDBBuilder:
    def build(self, incremental=True):
        """Build or update vector database"""

        # 1. Initialize ChromaDB
        self.initialize_chromadb(incremental)

        # 2. Load data
        existing_ids = set() if not incremental else self._get_existing_ids()
        data = self.load_data(existing_ids)

        # 3. Generate embeddings
        embeddings = self.generate_embeddings(data['documents'])

        # 4. Add to database
        self.add_to_collection(
            documents=data['documents'],
            embeddings=embeddings,
            metadatas=data['metadatas'],
            ids=data['ids']
        )

        # 5. Save summary
        self.save_build_summary(data, embeddings)
```

**Incremental mode:**

- Only processes NEW documents
- Skips existing ones (checks by ID)
- Much faster for updates

### D. Query Interface (`query_vectordb.py`)

```python
class VectorDBQuery:
    def query(self, query_text, n_results=5, where=None):
        """Query the vector database"""

        # ChromaDB handles:
        # 1. Query embedding generation
        # 2. Similarity search
        # 3. Ranking results
        results = self.collection.query(
            query_texts=[query_text],
            n_results=n_results,
            where=where
        )

        return results

    def display_results(self, results, query_text):
        """Pretty print results"""
        for i, (doc, metadata, distance) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0],
            results['distances'][0]
        ), 1):
            similarity = 1 - distance  # Convert distance to similarity

            print(f"\nğŸ“Š Result {i} (Similarity: {similarity:.3f})")
            print(f"   Type: {metadata['content_type']}")
            print(f"   Entities: {metadata['medical_entities']}")
            print(f"\n   {doc[:300]}...")
```

### E. RAG Example (`rag_example.py`)

```python
class SimpleRAG:
    def retrieve_context(self, question, n_results=5):
        """Retrieve relevant chunks"""
        results = self.collection.query(
            query_texts=[question],
            n_results=n_results
        )
        return results['documents'][0]

    def generate_prompt(self, question, context_chunks):
        """Build augmented prompt"""
        context = "\n\n".join(context_chunks)

        prompt = f"""Based on medical guidelines:

{context}

Question: {question}

Answer:"""

        return prompt

    def answer_question(self, question):
        """Complete RAG pipeline"""
        # 1. Retrieve
        context_chunks = self.retrieve_context(question)

        # 2. Augment
        prompt = self.generate_prompt(question, context_chunks)

        # 3. Generate (with your LLM of choice)
        # answer = llm.generate(prompt)

        return prompt  # Ready for LLM
```

---

## 10. HOW TO USE IT

### Setup (One-Time)

```powershell
# 1. Navigate to project
cd "E:\Y4S1\Final Year Research Project\Nephro-AI"

# 2. Activate virtual environment
.venv\Scripts\Activate.ps1

# 3. Install dependencies
pip install -r requirements.txt

# 4. Verify OpenAI embeddings work
python scripts\openai_embeddings.py
```

### Rebuild Database (After OpenAI Migration)

```powershell
# REQUIRED: New embedding model has different dimensions
python scripts\build_vectordb.py --rebuild
```

Expected output:

```
======================================================================
  CHROMADB VECTOR DATABASE BUILDER
======================================================================
...
âœ… Database build complete!
   - Total documents: 197
   - Embedding dimension: 1536
   - Time taken: 2m 34s
```

### Query the Database

#### Simple Query

```powershell
python scripts\query_vectordb.py "What is chronic kidney disease?"
```

#### Interactive Mode

```powershell
python scripts\query_vectordb.py

# Then type queries:
ğŸ” Query: What are CKD treatment options?
ğŸ” Query: filter:recommendation diabetes
ğŸ” Query: stats
ğŸ” Query: quit
```

#### From Python Code

```python
import chromadb

# Connect
client = chromadb.PersistentClient(path="vectordb/chroma_db")
collection = client.get_collection("nephro_ai_medical_kb")

# Query
results = collection.query(
    query_texts=["What is CKD?"],
    n_results=5
)

# Display
for doc in results['documents'][0]:
    print(doc)
```

### Build RAG Application

```python
# 1. Install LLM library
pip install openai  # or anthropic, or google-generativeai

# 2. Use rag_example.py as template
from rag_example import SimpleRAG

rag = SimpleRAG()
prompt = rag.answer_question("What dietary changes help CKD patients?")

# 3. Send to LLM
import openai
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt}]
)

print(response.choices[0].message.content)
```

---

## 11. ADVANCED TOPICS

### A. Incremental Database Updates

**Scenario:** You add new PDF documents to `data/raw/`.

**Process:**

```powershell
# 1. Extract new PDFs
python scripts\pdf_extractor.py

# 2. Prepare for vectordb
python scripts\prepare_vectordb.py

# 3. Incremental build (only adds new documents)
python scripts\build_vectordb.py

# Note: No --rebuild flag = incremental mode
```

**How it works:**

- Checks existing document IDs
- Only processes new ones
- Much faster than full rebuild

### B. Custom Metadata Filters

```python
# Filter by multiple criteria
results = collection.query(
    query_texts=["diabetes treatment"],
    where={
        "$and": [
            {"content_type": "recommendation"},
            {"has_diabetes": True},
            {"word_count": {"$gte": 200}}  # At least 200 words
        ]
    },
    n_results=10
)
```

### C. Hybrid Search (Coming Soon)

Combine semantic search with keyword search:

```python
# Semantic: Find meaning
semantic_results = collection.query(query_texts=["kidney failure"])

# Keyword: Find exact terms
keyword_results = collection.query(
    where_document={"$contains": "end-stage renal disease"}
)

# Combine with custom weighting
final_results = merge(semantic_results, keyword_results, weights=[0.7, 0.3])
```

### D. Multi-Collection Setup

For different medical domains:

```python
# Create separate collections
ckd_collection = client.get_or_create_collection("ckd_guidelines")
diabetes_collection = client.get_or_create_collection("diabetes_guidelines")
cardio_collection = client.get_or_create_collection("cardio_guidelines")

# Query all
def query_all_domains(question):
    results = []
    for collection in [ckd_collection, diabetes_collection, cardio_collection]:
        results.extend(collection.query(query_texts=[question], n_results=3))
    return results
```

### E. Performance Optimization

**1. Batch Size Tuning**

```python
# Experiment with different batch sizes
for batch_size in [50, 100, 200]:
    time = measure_time(lambda: build_with_batch_size(batch_size))
    print(f"Batch size {batch_size}: {time}s")
```

**2. Caching Frequent Queries**

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_query(query_text):
    return collection.query(query_texts=[query_text])
```

**3. Async Processing**

```python
import asyncio
import aiohttp

async def async_embed(texts):
    # Generate embeddings concurrently
    tasks = [embed_batch(batch) for batch in batches]
    return await asyncio.gather(*tasks)
```

---

## 12. REAL-WORLD APPLICATIONS

### A. Medical Chatbot

**Architecture:**

```
User: "I have stage 3 CKD. What should I eat?"
  â†“
Query vectordb â†’ Get relevant dietary guidelines
  â†“
Build context â†’ Combine with user question
  â†“
Send to LLM â†’ GPT-4/Claude generates personalized answer
  â†“
Response: "For stage 3 CKD, dietary recommendations include..."
```

**Implementation:**

```python
def chatbot(user_question, user_profile):
    # Retrieve relevant medical knowledge
    context = retrieve_context(user_question)

    # Build personalized prompt
    prompt = f"""
    Patient profile: {user_profile}
    Medical guidelines: {context}
    Question: {user_question}

    Provide personalized, evidence-based advice.
    """

    # Generate answer
    answer = llm.generate(prompt)

    return answer
```

### B. Clinical Decision Support

**Use case:** Help doctors find relevant treatment guidelines

```python
def clinical_support(patient_data, clinical_question):
    # Extract relevant medical entities from patient data
    entities = extract_medical_entities(patient_data)

    # Query with patient context
    results = collection.query(
        query_texts=[clinical_question],
        where={
            "$or": [
                {"has_" + entity: True}
                for entity in entities
            ]
        },
        n_results=10
    )

    # Rank by relevance to patient
    ranked = rank_by_patient_relevance(results, patient_data)

    return ranked
```

### C. Patient Education Platform

**Features:**

- Q&A about kidney disease
- Personalized education materials
- Treatment option comparison

**Implementation:**

```python
class PatientEducation:
    def explain_condition(self, condition):
        # Query for definitions and general info
        results = collection.query(
            query_texts=[condition],
            where={"content_type": {"$in": ["definition", "general"]}},
            n_results=5
        )

        # Generate patient-friendly explanation
        technical_content = results['documents'][0]
        simple_explanation = simplify_medical_text(technical_content)

        return simple_explanation

    def compare_treatments(self, condition):
        # Query for treatment options
        results = collection.query(
            query_texts=[f"{condition} treatment options"],
            where={"content_type": "recommendation"},
            n_results=20
        )

        # Extract and compare treatments
        treatments = extract_treatments(results)
        comparison = create_comparison_table(treatments)

        return comparison
```

### D. Research Assistant

**Use case:** Help researchers find relevant medical evidence

```python
def research_assistant(research_question):
    # Query for evidence and studies
    results = collection.query(
        query_texts=[research_question],
        where={"content_type": {"$in": ["evidence", "reference"]}},
        n_results=50
    )

    # Cluster by topic
    clusters = cluster_by_topic(results)

    # Generate research summary
    summary = summarize_evidence(clusters)

    # Identify gaps
    gaps = identify_research_gaps(clusters)

    return {
        "summary": summary,
        "evidence": results,
        "gaps": gaps
    }
```

### E. API Service

**Build a REST API for your vector database:**

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(title="Nephro-AI API")

class Query(BaseModel):
    question: str
    n_results: int = 5
    filters: dict = None

@app.post("/query")
def query_knowledge_base(query: Query):
    results = collection.query(
        query_texts=[query.question],
        n_results=query.n_results,
        where=query.filters
    )

    return {
        "question": query.question,
        "results": format_results(results)
    }

@app.post("/rag")
def rag_answer(query: Query):
    # Retrieve
    context = retrieve_context(query.question)

    # Generate
    answer = llm.generate(build_prompt(query.question, context))

    return {
        "question": query.question,
        "answer": answer,
        "sources": context
    }
```

Run with:

```powershell
uvicorn api:app --reload
```

Access at: http://localhost:8000

---

## ğŸ“ SUMMARY: Key Takeaways

### Core Concepts

1. **Embeddings**: Text â†’ Numbers that capture meaning (1536 dimensions)
2. **Vector Database**: Stores embeddings, enables semantic search
3. **Semantic Search**: Finds meaning, not just keywords
4. **RAG**: Retrieve + Augment + Generate = Accurate AI answers

### Architecture

```
PDFs â†’ Extract â†’ Chunk â†’ Filter â†’ Embed â†’ Store â†’ Query â†’ RAG
```

### Key Files

- `config.py`: Central configuration
- `openai_embeddings.py`: OpenAI API wrapper
- `build_vectordb.py`: Build database
- `query_vectordb.py`: Query interface
- `rag_example.py`: RAG template

### Commands

```powershell
# Setup
pip install -r requirements.txt

# Test embeddings
python scripts\openai_embeddings.py

# Build database
python scripts\build_vectordb.py --rebuild

# Query
python scripts\query_vectordb.py "your question"
```

### Applications

- Medical chatbots
- Clinical decision support
- Patient education
- Research assistants
- API services

---

## ğŸš€ NEXT STEPS

### For Learning

1. Read through each script
2. Run example queries
3. Modify and experiment
4. Build a simple RAG app

### For Development

1. Add more medical documents
2. Customize metadata filtering
3. Build web interface (Streamlit/Gradio)
4. Deploy as API (FastAPI)
5. Integrate with LLM (GPT-4/Claude)

### For Production

1. Secure API keys (environment variables)
2. Add authentication
3. Implement rate limiting
4. Monitor API costs
5. Add logging and analytics

---

## ğŸ“š FURTHER RESOURCES

### Vector Databases

- ChromaDB Docs: https://docs.trychroma.com
- HNSW Algorithm: https://arxiv.org/abs/1603.09320

### Embeddings

- OpenAI Embeddings: https://platform.openai.com/docs/guides/embeddings
- Sentence Transformers: https://www.sbert.net

### RAG

- LangChain: https://python.langchain.com/docs/use_cases/question_answering
- LlamaIndex: https://docs.llamaindex.ai

### Medical NLP

- KDIGO Guidelines: https://kdigo.org
- Medical Entity Recognition: https://github.com/NLPatVCU/medaCy

---

**Congratulations!** You now understand the complete Nephro-AI system from fundamentals to advanced applications. You're ready to build intelligent medical AI applications! ğŸ‰

**Questions? Experiment and learn by doing!** ğŸš€
