# ğŸ¥ Nephro-AI - PDF Knowledge Extraction Pipeline

## âœ… Project Status: READY FOR VECTORIZATION

A complete pipeline for extracting, processing, and preparing medical knowledge from PDF documents for vector database storage and semantic search.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Processing Results](#processing-results)
- [File Structure](#file-structure)
- [Scripts](#scripts)
- [Data Format](#data-format)
- [Next Steps](#next-steps)

## ğŸ¯ Overview

This project processes the **KDIGO 2024 Clinical Practice Guideline for CKD** (199 pages) into **197 high-quality, vectorization-ready text chunks** with rich metadata for semantic search and RAG applications.

### Pipeline Flow

```
PDF â†’ Extract â†’ Clean â†’ Chunk â†’ Filter â†’ Metadata â†’ VectorDB Ready
```

## âœ¨ Features

### Text Processing
- âœ… Multi-method PDF extraction (pdfplumber + PyPDF2)
- âœ… Intelligent text cleaning and normalization
- âœ… Medical terminology preservation
- âœ… Smart sentence-based chunking with overlap

### Metadata Enrichment
- âœ… Automatic medical entity detection (CKD, GFR, diabetes, etc.)
- âœ… Content type classification (recommendation, evidence, definition)
- âœ… Section detection
- âœ… 12 metadata fields per chunk

### Quality Assurance
- âœ… Quality filtering (81% retention rate)
- âœ… Medical keyword validation
- âœ… Reference/citation filtering
- âœ… Length optimization (50-600 words)

### Output
- âœ… ChromaDB-ready format
- âœ… JSON and human-readable TXT
- âœ… Comprehensive statistics
- âœ… 30 sample test queries

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- Virtual environment (recommended)

### Setup

```bash
# Clone repository
cd Nephro-AI

# Create and activate virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### Required Libraries

```bash
pip install chromadb sentence-transformers tqdm transformers
pip install PyPDF2 pdfplumber pillow nltk spacy langdetect beautifulsoup4 lxml
```

## ğŸ® Quick Start

### 1. Process PDF Document

```bash
python scripts/pdf_extractor.py
```

**Output**: 243 initial chunks with metadata

### 2. Analyze Results (Optional)

```bash
python scripts/analyze_chunks.py
```

**Output**: Statistics and readable text file

### 3. Prepare for Vector Database

```bash
python scripts/prepare_vectordb.py
```

**Output**: 197 quality-filtered, ChromaDB-ready chunks

### 4. Explore Data

```bash
python scripts/quick_start.py
```

**Output**: Interactive data exploration

## ğŸ“Š Processing Results

### Source Document
| Metric | Value |
|--------|-------|
| Pages | 199 |
| Raw Characters | 936,183 |
| Cleaned Characters | 944,430 |

### Output Chunks
| Metric | Value |
|--------|-------|
| Total Chunks | 243 |
| Quality Filtered | 197 (81%) |
| Average Size | 485 words |
| Size Range | 190-500 words |

### Content Distribution
| Type | Count | % |
|------|-------|---|
| Recommendations | 128 | 65.0% |
| References | 46 | 23.4% |
| Evidence | 16 | 8.1% |
| Definitions | 4 | 2.0% |
| General | 3 | 1.5% |

### Medical Entity Coverage
| Entity | Chunks | Coverage |
|--------|--------|----------|
| CKD | 181 | 91.9% |
| GFR | 145 | 73.6% |
| Diabetes | 66 | 33.5% |
| Dialysis | 42 | 21.3% |
| Hypertension | 29 | 14.7% |

## ğŸ“ File Structure

```
Nephro-AI/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ medical_knowledge/
â”‚   â”‚       â”œâ”€â”€ diseases/              # Disease information
â”‚   â”‚       â”œâ”€â”€ treatments/            # Treatment procedures
â”‚   â”‚       â”œâ”€â”€ diagnostics/           # Diagnostic tests
â”‚   â”‚       â”œâ”€â”€ medications/           # Medication info
â”‚   â”‚       â”œâ”€â”€ nutrition/             # Dietary guidelines
â”‚   â”‚       â””â”€â”€ prevention/            # Prevention strategies
â”‚   â”‚
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ KDIGO-2024-CKD-Guideline_chunks.json       âœ…
â”‚       â”œâ”€â”€ KDIGO-2024-CKD-Guideline_metadata.json     âœ…
â”‚       â”œâ”€â”€ KDIGO-2024-CKD-Guideline_readable.txt      âœ…
â”‚       â”œâ”€â”€ vectordb_ready_chunks.json                 âœ…
â”‚       â”œâ”€â”€ vectordb_preparation_summary.json          âœ…
â”‚       â”œâ”€â”€ sample_queries.txt                         âœ…
â”‚       â”œâ”€â”€ PROCESSING_PIPELINE.md                     âœ…
â”‚       â””â”€â”€ PROCESSING_SUMMARY.md                      âœ…
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ pdf_extractor.py          # Extract & chunk PDF
â”‚   â”œâ”€â”€ analyze_chunks.py         # Analyze results
â”‚   â”œâ”€â”€ prepare_vectordb.py       # Prepare for ChromaDB
â”‚   â””â”€â”€ quick_start.py            # Demo & exploration
â”‚
â”œâ”€â”€ vectordb/
â”‚   â””â”€â”€ chroma_db/                # ChromaDB storage (ready)
â”‚
â””â”€â”€ logs/                         # Operation logs
```

## ğŸ”§ Scripts

### `pdf_extractor.py`
Extracts text from PDF, cleans, chunks, and adds metadata.

**Configuration**:
```python
CHUNK_SIZE = 500   # Target words per chunk
OVERLAP = 50       # Words overlap between chunks
```

### `analyze_chunks.py`
Generates statistics and readable output.

### `prepare_vectordb.py`
Filters quality chunks and prepares ChromaDB format.

**Quality Filters**:
```python
MIN_WORDS = 50
MAX_WORDS = 600
MIN_MEDICAL_KEYWORDS = 2
```

### `quick_start.py`
Interactive exploration and usage examples.

## ğŸ“ Data Format

### ChromaDB-Ready Structure

```json
{
  "documents": ["text chunk 1", "text chunk 2", ...],
  "metadatas": [
    {
      "source": "KDIGO-2024-CKD-Guideline.pdf",
      "chunk_id": 0,
      "content_type": "recommendation",
      "word_count": 495,
      "has_ckd": true,
      "has_gfr": true,
      "medical_entities": "CKD,GFR,albuminuria",
      "year": "2024",
      "organization": "KDIGO"
    },
    ...
  ],
  "ids": ["kdigo_2024_0", "kdigo_2024_1", ...]
}
```

### Metadata Fields

| Field | Type | Description |
|-------|------|-------------|
| source | string | Source PDF filename |
| chunk_id | int | Unique chunk identifier |
| content_type | string | recommendation, evidence, definition, etc. |
| word_count | int | Number of words in chunk |
| has_ckd | bool | Contains CKD entity |
| has_gfr | bool | Contains GFR entity |
| has_diabetes | bool | Contains diabetes entity |
| has_hypertension | bool | Contains hypertension entity |
| has_dialysis | bool | Contains dialysis entity |
| medical_entities | string | Comma-separated entities |
| year | string | Publication year |
| organization | string | Source organization |
| section | string | Document section (optional) |

## ğŸ¯ Next Steps

### 1. Build Vector Database

```python
import chromadb
import json

# Load processed data
with open('data/processed/vectordb_ready_chunks.json', 'r') as f:
    data = json.load(f)

# Initialize ChromaDB
client = chromadb.PersistentClient(path="./vectordb/chroma_db")

# Create collection
collection = client.create_collection(
    name="kdigo_ckd_guidelines",
    metadata={"description": "KDIGO 2024 CKD Guidelines"}
)

# Add documents
collection.add(
    documents=data['documents'],
    metadatas=data['metadatas'],
    ids=data['ids']
)

print(f"âœ… Added {len(data['documents'])} documents to ChromaDB")
```

### 2. Query Vector Database

```python
# Search for similar content
results = collection.query(
    query_texts=["What is chronic kidney disease?"],
    n_results=5,
    where={"content_type": "recommendation"}  # Filter by metadata
)

# Display results
for i, (doc, metadata) in enumerate(zip(results['documents'][0], results['metadatas'][0])):
    print(f"\n{i+1}. {metadata['content_type']} - {metadata['medical_entities']}")
    print(f"   {doc[:200]}...")
```

### 3. Test Sample Queries

Use the 30 sample queries in `data/processed/sample_queries.txt`:
- General CKD information
- GFR and measurements
- Treatment options
- Risk factors and complications
- Monitoring and management

### 4. Integration Options

- **RAG System**: Use for retrieval-augmented generation
- **Chatbot**: Build medical Q&A assistant
- **Search API**: Create semantic search endpoint
- **Knowledge Base**: Integrate with clinical systems

## ğŸ“– Documentation

- **[PROCESSING_PIPELINE.md](data/processed/PROCESSING_PIPELINE.md)** - Detailed pipeline documentation
- **[PROCESSING_SUMMARY.md](data/processed/PROCESSING_SUMMARY.md)** - Processing results summary
- **[sample_queries.txt](data/processed/sample_queries.txt)** - Test queries

## ğŸ“ Use Cases

1. **Clinical Decision Support**: Retrieve relevant guidelines
2. **Medical Education**: Q&A system for medical students
3. **Research**: Find evidence-based recommendations
4. **Patient Information**: Generate patient-friendly explanations
5. **Quality Assurance**: Validate clinical protocols

## ğŸ” Sample Queries

```python
# Load sample queries
with open('data/processed/sample_queries.txt', 'r') as f:
    queries = [line.strip() for line in f if line.strip() and not line.startswith('=')]

# Test each query
for query in queries[:5]:  # First 5 queries
    results = collection.query(query_texts=[query], n_results=3)
    print(f"\nQuery: {query}")
    print(f"Top result: {results['documents'][0][0][:150]}...")
```

## ğŸ“ˆ Statistics

| Metric | Value |
|--------|-------|
| Extraction Success | 100% |
| Quality Retention | 81.1% |
| CKD Coverage | 91.9% |
| GFR Coverage | 73.6% |
| Avg Chunk Quality Score | High |
| Ready for Production | âœ… Yes |

## ğŸ¤ Contributing

To add more medical knowledge:

1. Add PDF to `data/raw/`
2. Run extraction pipeline
3. Verify quality filtering
4. Update vector database

## ğŸ“„ License

KDIGO guidelines are Â© KDIGO. Processing pipeline is open source.

## ğŸ‰ Success!

**All files processed and ready for vectorization!**

- âœ… 197 high-quality chunks
- âœ… Rich metadata (12 fields)
- âœ… Medical entity tagging
- âœ… ChromaDB-ready format
- âœ… Sample queries included
- âœ… Complete documentation

---

**Version**: 1.0  
**Last Updated**: October 19, 2025  
**Status**: Production Ready âœ…
