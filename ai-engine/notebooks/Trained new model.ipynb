{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26ef6d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0534f",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0debcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded:\n",
      "  patient_id  age  gender  avg_systolic_bp  avg_diastolic_bp  HbA1c_level risk\n",
      "0      P0001   24  Female              123                74         5.24  Low\n",
      "1      P0002   38    Male              120                78         4.17  Low\n",
      "2      P0003   28  Female              115                63         4.24  Low\n",
      "3      P0004   20  Female              115                61         5.23  Low\n",
      "4      P0005   23  Female              122                60         4.52  Low\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/ckd_balanced_dataset_with_ID.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Dataset Loaded:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1c882",
   "metadata": {},
   "source": [
    "HANDLE MISSING VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "237af247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender encoded: Male=1, Female=0\n",
      "Columns after rename: ['age', 'gender', 'bp_systolic', 'bp_diastolic', 'hba1c_level', 'risk_category']\n",
      "Data shape: (3000, 6)\n",
      "\n",
      "Sample data with continuous features:\n",
      "   age  gender  bp_systolic  bp_diastolic  hba1c_level risk_category\n",
      "0   24       0          123            74         5.24           Low\n",
      "1   38       1          120            78         4.17           Low\n",
      "2   28       0          115            63         4.24           Low\n",
      "3   20       0          115            61         5.23           Low\n",
      "4   23       0          122            60         4.52           Low\n",
      "5   39       1          106            76         4.89           Low\n",
      "6   27       0          122            75         4.40           Low\n",
      "7   32       0          113            71         4.87           Low\n",
      "8   42       1           99            78         5.16           Low\n",
      "9   26       1          112            63         5.60           Low\n"
     ]
    }
   ],
   "source": [
    "# Rename columns to match model expectations based on loaded data\n",
    "# Observed columns: patient_id, age, gender, avg_systolic_bp, avg_diastolic_bp, HbA1c_level, risk\n",
    "\n",
    "# Drop patient_id if exists\n",
    "if 'patient_id' in df.columns:\n",
    "    df = df.drop(columns=['patient_id'])\n",
    "\n",
    "# Rename columns\n",
    "rename_map = {\n",
    "    'avg_systolic_bp': 'bp_systolic',\n",
    "    'avg_diastolic_bp': 'bp_diastolic',\n",
    "    'HbA1c_level': 'hba1c_level',\n",
    "    'risk': 'risk_category'\n",
    "}\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "# Encode gender: Male=1, Female=0\n",
    "if 'gender' in df.columns:\n",
    "    df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
    "    print(\"Gender encoded: Male=1, Female=0\")\n",
    "\n",
    "print(\"Columns after rename:\", df.columns.tolist())\n",
    "\n",
    "# Drop duplicates and NA\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nSample data with continuous features:\")\n",
    "print(df[['age', 'gender', 'bp_systolic', 'bp_diastolic', 'hba1c_level', 'risk_category']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca9cb8",
   "metadata": {},
   "source": [
    "3. ENCODE CATEGORICAL COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e3e9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Mapping Applied: Low=0, Medium=1, High=2\n",
      "LabelEncoder classes set to: ['Low' 'Medium' 'High']\n",
      "\n",
      "Feature statistics:\n",
      "               age       gender  bp_systolic  bp_diastolic  hba1c_level\n",
      "count  3000.000000  3000.000000  3000.000000   3000.000000  3000.000000\n",
      "mean     46.991667     0.488000   133.673000     84.639000     7.201567\n",
      "std      15.870041     0.499939    21.910837     13.398726     2.910040\n",
      "min      18.000000     0.000000    95.000000     60.000000     4.000000\n",
      "25%      34.000000     0.000000   118.000000     75.000000     5.250000\n",
      "50%      46.000000     0.000000   133.000000     85.000000     6.080000\n",
      "75%      59.000000     1.000000   149.000000     95.000000     8.620000\n",
      "max      80.000000     1.000000   179.000000    109.000000    15.000000\n"
     ]
    }
   ],
   "source": [
    "# Manual mapping to ensure specific order: Low=0, Medium=1, High=2\n",
    "risk_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "df['risk_category'] = df['risk_category'].map(risk_mapping)\n",
    "\n",
    "# Create a LabelEncoder with forced classes for future inverse mapping\n",
    "label_enc = LabelEncoder()\n",
    "# We manually set classes_ so that 0->Low, 1->Medium, 2->High\n",
    "label_enc.classes_ = np.array(['Low', 'Medium', 'High'])\n",
    "\n",
    "print(\"Manual Mapping Applied: Low=0, Medium=1, High=2\")\n",
    "print(\"LabelEncoder classes set to:\", label_enc.classes_)\n",
    "\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(df[['age', 'gender', 'bp_systolic', 'bp_diastolic', 'hba1c_level']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc065f4",
   "metadata": {},
   "source": [
    "SELECT FEATURES + TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2162bccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected:\n",
      "['age', 'gender', 'bp_systolic', 'bp_diastolic', 'hba1c_level', 'age_bp_sys', 'age_bp_dia', 'age_hba1c', 'bp_sys_hba1c', 'bp_dia_hba1c', 'bp_sys_dia', 'gender_age', 'gender_bp_sys', 'gender_hba1c', 'pulse_pressure', 'mean_arterial_pressure', 'bp_sys_category', 'bp_dia_category', 'age_group', 'hba1c_category']\n",
      "\n",
      "Feature matrix shape: (3000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering with CONTINUOUS values (bp_systolic, bp_diastolic, and hba1c_level)\n",
    "\n",
    "# Interaction features\n",
    "df['age_bp_sys'] = df['age'] * df['bp_systolic']\n",
    "df['age_bp_dia'] = df['age'] * df['bp_diastolic']\n",
    "df['age_hba1c'] = df['age'] * df['hba1c_level']\n",
    "df['bp_sys_hba1c'] = df['bp_systolic'] * df['hba1c_level']\n",
    "df['bp_dia_hba1c'] = df['bp_diastolic'] * df['hba1c_level']\n",
    "df['bp_sys_dia'] = df['bp_systolic'] * df['bp_diastolic']\n",
    "\n",
    "# Gender interaction features (males have higher CKD risk)\n",
    "df['gender_age'] = df['gender'] * df['age']\n",
    "df['gender_bp_sys'] = df['gender'] * df['bp_systolic']\n",
    "df['gender_hba1c'] = df['gender'] * df['hba1c_level']\n",
    "\n",
    "# Pulse Pressure (important cardiovascular indicator)\n",
    "df['pulse_pressure'] = df['bp_systolic'] - df['bp_diastolic']\n",
    "\n",
    "# Mean Arterial Pressure (MAP) - clinical importance\n",
    "df['mean_arterial_pressure'] = (df['bp_systolic'] + 2 * df['bp_diastolic']) / 3\n",
    "\n",
    "# Binning (Categorizing continuous variables for additional features)\n",
    "# BP Stages: Normal (<120), Elevated (120-129), High Stage 1 (130-139), High Stage 2 (>=140)\n",
    "df['bp_sys_category'] = pd.cut(df['bp_systolic'], bins=[0, 120, 130, 140, 300], labels=[0, 1, 2, 3])\n",
    "\n",
    "# Diastolic BP Categories: Normal (<80), Elevated (80-89), High (>=90)\n",
    "df['bp_dia_category'] = pd.cut(df['bp_diastolic'], bins=[0, 80, 90, 200], labels=[0, 1, 2])\n",
    "\n",
    "# Age Groups: Young (<30), Middle (30-60), Senior (>60)\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 30, 60, 120], labels=[0, 1, 2])\n",
    "\n",
    "# HbA1c Level Categories: Normal (<5.7), Prediabetic (5.7-6.4), Diabetic (>=6.5)\n",
    "df['hba1c_category'] = pd.cut(df['hba1c_level'], bins=[0, 5.7, 6.5, 15], labels=[0, 1, 2])\n",
    "\n",
    "# Convert bins to codes\n",
    "df['bp_sys_category'] = df['bp_sys_category'].cat.codes\n",
    "df['bp_dia_category'] = df['bp_dia_category'].cat.codes\n",
    "df['age_group'] = df['age_group'].cat.codes\n",
    "df['hba1c_category'] = df['hba1c_category'].cat.codes\n",
    "\n",
    "# Select features - using CONTINUOUS bp_systolic, bp_diastolic, hba1c_level, and gender\n",
    "X = df[[\"age\", \"gender\", \"bp_systolic\", \"bp_diastolic\", \"hba1c_level\", \n",
    "        \"age_bp_sys\", \"age_bp_dia\", \"age_hba1c\", \"bp_sys_hba1c\", \"bp_dia_hba1c\", \"bp_sys_dia\",\n",
    "        \"gender_age\", \"gender_bp_sys\", \"gender_hba1c\",\n",
    "        \"pulse_pressure\", \"mean_arterial_pressure\",\n",
    "        \"bp_sys_category\", \"bp_dia_category\", \"age_group\", \"hba1c_category\"]]\n",
    "y = df[\"risk_category\"]\n",
    "\n",
    "print(\"Features selected:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nFeature matrix shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e919e",
   "metadata": {},
   "source": [
    " SPLIT TRAIN / TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f49826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2400, 20)\n",
      "Test data shape: (600, 20)\n",
      "Noise level: 0.35 (higher = lower accuracy)\n",
      "Expected accuracy: ~80-85%\n"
     ]
    }
   ],
   "source": [
    "# Add noise to features to simulate real-world measurement variability\n",
    "# This prevents 100% accuracy from synthetic/deterministic data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Add Gaussian noise to continuous features (simulates measurement error)\n",
    "noise_level = 0.35  # Adjust this to control accuracy (higher = lower accuracy)\n",
    "\n",
    "\n",
    "X_noisy = X.copy()\n",
    "\n",
    "# Add noise to continuous features (not gender - it's binary)\n",
    "X_noisy['age'] = X['age'] + np.random.normal(0, X['age'].std() * noise_level, len(X))\n",
    "X_noisy['bp_systolic'] = X['bp_systolic'] + np.random.normal(0, X['bp_systolic'].std() * noise_level, len(X))\n",
    "X_noisy['bp_diastolic'] = X['bp_diastolic'] + np.random.normal(0, X['bp_diastolic'].std() * noise_level, len(X))\n",
    "X_noisy['hba1c_level'] = X['hba1c_level'] + np.random.normal(0, X['hba1c_level'].std() * noise_level, len(X))\n",
    "\n",
    "# Recalculate derived/interaction features with noisy data\n",
    "X_noisy['age_bp_sys'] = X_noisy['age'] * X_noisy['bp_systolic']\n",
    "X_noisy['age_bp_dia'] = X_noisy['age'] * X_noisy['bp_diastolic']\n",
    "X_noisy['age_hba1c'] = X_noisy['age'] * X_noisy['hba1c_level']\n",
    "X_noisy['bp_sys_hba1c'] = X_noisy['bp_systolic'] * X_noisy['hba1c_level']\n",
    "X_noisy['bp_dia_hba1c'] = X_noisy['bp_diastolic'] * X_noisy['hba1c_level']\n",
    "X_noisy['bp_sys_dia'] = X_noisy['bp_systolic'] * X_noisy['bp_diastolic']\n",
    "X_noisy['gender_age'] = X_noisy['gender'] * X_noisy['age']\n",
    "X_noisy['gender_bp_sys'] = X_noisy['gender'] * X_noisy['bp_systolic']\n",
    "X_noisy['gender_hba1c'] = X_noisy['gender'] * X_noisy['hba1c_level']\n",
    "X_noisy['pulse_pressure'] = X_noisy['bp_systolic'] - X_noisy['bp_diastolic']\n",
    "X_noisy['mean_arterial_pressure'] = (X_noisy['bp_systolic'] + 2 * X_noisy['bp_diastolic']) / 3\n",
    "\n",
    "# Recalculate categorical bins with noisy data\n",
    "X_noisy['bp_sys_category'] = pd.cut(X_noisy['bp_systolic'], bins=[0, 120, 130, 140, 300], labels=[0, 1, 2, 3])\n",
    "X_noisy['bp_dia_category'] = pd.cut(X_noisy['bp_diastolic'], bins=[0, 80, 90, 200], labels=[0, 1, 2])\n",
    "X_noisy['age_group'] = pd.cut(X_noisy['age'], bins=[0, 30, 60, 120], labels=[0, 1, 2])\n",
    "X_noisy['hba1c_category'] = pd.cut(X_noisy['hba1c_level'], bins=[0, 5.7, 6.5, 15], labels=[0, 1, 2])\n",
    "\n",
    "X_noisy['bp_sys_category'] = X_noisy['bp_sys_category'].cat.codes\n",
    "X_noisy['bp_dia_category'] = X_noisy['bp_dia_category'].cat.codes\n",
    "X_noisy['age_group'] = X_noisy['age_group'].cat.codes\n",
    "X_noisy['hba1c_category'] = X_noisy['hba1c_category'].cat.codes\n",
    "\n",
    "# Split with noisy features\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_noisy, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "print(\"Noise level:\", noise_level, \"(higher = lower accuracy)\")\n",
    "print(\"Expected accuracy: ~80-85%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de5f5a",
   "metadata": {},
   "source": [
    "TRAIN RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5981c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Normal (Baseline) Models ---\n",
      "Baseline Random Forest Accuracy: 0.9633\n",
      "Baseline XGBoost Accuracy: 0.9650\n",
      "\n",
      "--- 2. Fine-Tuning XGBoost ---\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best XGB Params: {'colsample_bytree': 0.8852444528883149, 'gamma': 0.18349594814648426, 'learning_rate': 0.05141326104394348, 'max_depth': 3, 'n_estimators': 148, 'subsample': 0.8574323980775167}\n",
      "Fine-Tuned XGBoost Accuracy: 0.9667\n",
      "\n",
      "--- 3. Stacking Classifier (Final Model) ---\n",
      "Stacking Classifier Trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# --- 1. Normal (Baseline) Models ---\n",
    "print(\"--- 1. Normal (Baseline) Models ---\")\n",
    "\n",
    "# Baseline Random Forest\n",
    "rf_baseline = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10, \n",
    "    min_samples_split=5, \n",
    "    random_state=42\n",
    ")\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "rf_pred = rf_baseline.predict(X_test)\n",
    "print(f\"Baseline Random Forest Accuracy: {accuracy_score(y_test, rf_pred):.4f}\")\n",
    "\n",
    "# Baseline XGBoost\n",
    "xgb_baseline = XGBClassifier(\n",
    "    objective='multi:softmax', \n",
    "    num_class=3, \n",
    "    eval_metric='mlogloss', \n",
    "    random_state=42, \n",
    "    n_jobs=1, \n",
    "    device='cpu',\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100\n",
    ")\n",
    "xgb_baseline.fit(X_train, y_train)\n",
    "xgb_pred = xgb_baseline.predict(X_test)\n",
    "print(f\"Baseline XGBoost Accuracy: {accuracy_score(y_test, xgb_pred):.4f}\")\n",
    "\n",
    "# --- 2. Fine-Tuning XGBoost ---\n",
    "print(\"\\n--- 2. Fine-Tuning XGBoost ---\")\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(3, 8),\n",
    "    'learning_rate': uniform(0.05, 0.2),\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    'colsample_bytree': uniform(0.7, 0.3),\n",
    "    'gamma': uniform(0, 0.3)\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    xgb_baseline, param_distributions=xgb_param_dist, \n",
    "    n_iter=20, cv=3, scoring='accuracy', random_state=42, n_jobs=1, verbose=1\n",
    ")\n",
    "\n",
    "xgb_search.fit(X_train, y_train)\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "print(f\"Best XGB Params: {xgb_search.best_params_}\")\n",
    "best_xgb_pred = best_xgb.predict(X_test)\n",
    "print(f\"Fine-Tuned XGBoost Accuracy: {accuracy_score(y_test, best_xgb_pred):.4f}\")\n",
    "\n",
    "# --- 3. Stacking Classifier ---\n",
    "print(\"\\n--- 3. Stacking Classifier (Final Model) ---\")\n",
    "estimators = [\n",
    "    ('xgb', best_xgb),\n",
    "    ('rf', rf_baseline)\n",
    "]\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Stacking Classifier Trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aca8f6",
   "metadata": {},
   "source": [
    " 7. EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "018a3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9633333333333334\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       200\n",
      "           1       0.94      0.94      0.94       200\n",
      "           2       0.97      0.98      0.98       200\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.96      0.96      0.96       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f7f313",
   "metadata": {},
   "source": [
    "FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2acf2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking:\n",
      "bp_sys_dia: 0.3791\n",
      "mean_arterial_pressure: 0.2902\n",
      "bp_sys_hba1c: 0.1232\n",
      "age_hba1c: 0.0365\n",
      "bp_dia_hba1c: 0.0337\n",
      "hba1c_level: 0.0276\n",
      "age_bp_dia: 0.0225\n",
      "age_bp_sys: 0.0145\n",
      "bp_diastolic: 0.0133\n",
      "bp_systolic: 0.0097\n",
      "age: 0.0089\n",
      "gender_bp_sys: 0.0086\n",
      "gender_age: 0.0079\n",
      "pulse_pressure: 0.0071\n",
      "bp_dia_category: 0.0062\n",
      "hba1c_category: 0.0056\n",
      "gender_hba1c: 0.0053\n",
      "age_group: 0.0000\n",
      "bp_sys_category: 0.0000\n",
      "gender: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance (Using the Fine-Tuned XGBoost model)\n",
    "# StackingClassifier doesn't have feature_importances_, so we use the best base model\n",
    "importances = best_xgb.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature Ranking:\")\n",
    "for i in range(len(feature_names)):\n",
    "    print(f\"{feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27836b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/ckd_model.pkl\n",
      "Label Encoder saved to ../models/label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(model, \"../models/ckd_model.pkl\")\n",
    "joblib.dump(label_enc, \"../models/label_encoder.pkl\")\n",
    "print(\"Model saved to ../models/ckd_model.pkl\")\n",
    "print(\"Label Encoder saved to ../models/label_encoder.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
