"""
RAG Engine for Nephro-AI
Orchestrates the flow between NLU, VectorDB, Patient Data, and LLM.
"""

import sys
import hashlib
import time
from pathlib import Path
from typing import Dict, Any, List

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from chatbot.enhanced_query_vectordb import EnhancedVectorQuery
from chatbot.patient_data import PatientDataManager
from chatbot.llm_engine import LLMEngine
from utils.logger import ConsoleLogger as Log

class RAGEngine:
    def __init__(self):
        """Initialize all components"""
        Log.section("Initializing RAGEngine")
        self.vector_db = EnhancedVectorQuery()
        self.patient_data = PatientDataManager()
        self.llm = LLMEngine()
        self.cache = {} # Simple in-memory cache (Use Redis for production)
        Log.success("RAG Engine Ready")

    def get_cache_key(self, query, patient_id, target_lang):
        """Generate cache key that includes language to prevent wrong-language cached responses"""
        data_version = self.patient_data.get_last_update_timestamp(patient_id)
        raw_key = f"{patient_id}:{data_version}:{target_lang}:{query.lower().strip()}"
        return hashlib.md5(raw_key.encode()).hexdigest()
    
    def clear_cache_for_patient(self, patient_id: str):
        """Clear all cached responses for a specific patient"""
        keys_to_remove = [k for k in self.cache.keys() if patient_id in str(k)]
        for key in keys_to_remove:
            del self.cache[key]
        Log.step("ðŸ—‘ï¸", "CACHE CLEARED", f"Removed {len(keys_to_remove)} entries for patient '{patient_id}'")
        return len(keys_to_remove)

    def _detect_output_language(self, text: str) -> str:
        """
        Determines the Response Language:
        - 'si' if input has Sinhala chars OR Singlish keywords.
        - 'en' if input has English keywords.
        """
        text_lower = f" {text.lower()} " # Pad text for safer matching

        # 1. CHECK FOR SINHALA UNICODE (Absolute Truth)
        if any('\u0D80' <= char <= '\u0DFF' for char in text):
            return 'si'

        # 2. CHECK FOR ENGLISH KEYWORDS
        # Added 'make', 'do', 'can' to cover more ground
        english_roots = [
            ' i ', ' my ', ' you ', ' the ', ' is ', ' are ', ' am ', 
            ' pain', ' hurt', ' ache', ' sick', ' doctor', ' hospital',
            ' kidney', ' stomach', ' head', ' leg', ' chest', ' breath',
            ' vomit', ' nausea', ' dizzy', ' fever', ' swell',
            ' what', ' where', ' when', ' how ', ' who', ' why',
            ' hi ', ' hello', ' hey', ' morning', ' evening', ' help',
            ' make ', ' do ', ' can ', ' to ', ' for '
        ]
        
        # 3. CHECK FOR SINGLISH KEYWORDS (FIXED: Padded short words)
        singlish_roots = [
            'mata', 'mage', 'oyage', 'ape', 'apata',
            'ridenawa', 'kakkuma', 'amaru', 'idimenawa', 'idimuma',
            'bada', 'oluwa', 'papuwa', 'kakula', 'atha',
            'mokakda', 'koheda', 'kawadada', 'kohomada',
            'podi', 'loku', 'godak', 'hari', 'tikak',
            'beheth', 'kanna', 'bonna', 'yanne', 'epaa',
            # âš ï¸ DANGEROUS SHORT WORDS (Now Padded with spaces)
            ' ai ', ' ne ', ' na ', ' ow ', ' le ', ' ane '
        ]

        # Count matches
        english_score = sum(1 for root in english_roots if root in text_lower)
        singlish_score = sum(1 for root in singlish_roots if root in text_lower)

        print(f"ðŸ” Lang Detect: English Score={english_score}, Singlish Score={singlish_score}")

        # LOGIC:
        if english_score > 0 and english_score >= singlish_score:
            return 'en'
        
        if singlish_score > 0:
            return 'si'
            
        return 'en'

    def process_query(self, query: str, patient_id: str = "default_patient", chat_history: List[Dict[str, str]] = []) -> Dict[str, Any]:
        Log.section(f"PROCESSING QUERY: '{query}'")

        # 1. DETERMINE OUTPUT LANGUAGE FIRST (before cache check)
        target_lang = self._detect_output_language(query)
        Log.step("ðŸ”", "Detecting Language", f"Result: {'SINHALA' if target_lang == 'si' else 'ENGLISH'}")

        # 2. CHECK CACHE (now includes language in key)
        cache_key = self.get_cache_key(query, patient_id, target_lang)
        if cache_key in self.cache:
            Log.step("âš¡", "CACHE HIT", f"Returning cached {target_lang.upper()} response")
            return self.cache[cache_key]

        # 3. BRIDGE LAYER (Hybrid Smart Route + MedDict Integration)
        # ============================================================
        # NEW ARCHITECTURE:
        # - Step 1: Always extract MedDict hints (fast, local)
        # - Step 2: Try Sinhala NLU with LaBSE (zero-shot, local)
        # - Step 3: If confidence high â†’ Use NLU + MedDict (fast path)
        # - Step 4: If confidence low â†’ Fallback to LLM API (smart path)
        # ============================================================
        english_query = query
        translation_method = "none"  # Track which method was used
        t_translation_start = time.time()
        
        if target_lang == 'si':
            Log.step("ðŸ”„", "NLU BRIDGE: Processing Sinhala (Hybrid Mode)...")
            
            # STEP 1: ALWAYS extract dictionary hints (fast operation, ~5ms)
            dict_hints_raw = self.llm._get_dictionary_hints(query)
            if dict_hints_raw:
                Log.step("ðŸ“–", "MedDict Hit", f"{{ {dict_hints_raw[:80]}{'...' if len(dict_hints_raw) > 80 else ''} }}")
            
            # STEP 2: Try Sinhala NLU with LaBSE (zero-shot intent detection, ~300ms)
            si_analysis = self.llm.sinhala_nlu.analyze_query(query)
            nlu_confidence = si_analysis['confidence']
            nlu_intent = si_analysis['detected_intent']
            
            Log.step("ðŸ§ ", "Sinhala NLU (LaBSE)", 
                    f"Intent: {nlu_intent} | Confidence: {nlu_confidence:.2%}")
            
            # STEP 3: Decision based on confidence threshold
            if nlu_confidence > 0.6:
                # ============ FAST PATH: NLU + MedDict ============
                translation_method = "sinhala_nlu"
                Log.step("âš¡", "FAST PATH", "Using Sinhala NLU + MedDict (no API call)")
                
                # Start with NLU's translated query
                english_query = si_analysis['translated_query']
                
                # Extract entities from NLU
                nlu_entities = si_analysis.get('entities', {})
                entity_terms = []
                for category, terms in nlu_entities.items():
                    entity_terms.extend(terms)
                
                # Enrich with MedDict entities (parse the hints string)
                meddict_terms = []
                if dict_hints_raw:
                    for hint in dict_hints_raw.split(','):
                        if '=' in hint:
                            try:
                                parts = hint.strip().split('=')
                                if len(parts) == 2:
                                    en_term = parts[1].strip().strip("'\"")
                                    if en_term and en_term not in meddict_terms:
                                        meddict_terms.append(en_term)
                            except:
                                pass
                
                # Build enhanced query: Intent + MedDict terms + NLU entities
                query_parts = [nlu_intent.replace('_', ' ')]
                query_parts.extend(meddict_terms[:5])  # Limit to top 5 MedDict terms
                query_parts.extend(entity_terms[:3])    # Add NLU entities
                
                # Construct final English query
                english_query = ' '.join(query_parts)
                
                # Clean up duplicates and format
                english_query = ' '.join(dict.fromkeys(english_query.split()))
                
                Log.step("  ", "Built Query", f"'{english_query}'")
                
            else:
                # ============ SMART PATH: LLM Fallback ============
                translation_method = "llm_api"
                Log.step("ðŸ§ ", "SMART PATH", f"NLU confidence too low ({nlu_confidence:.2%}), using LLM API...")
                english_query = self.llm.translate_to_english(query, chat_history)
                Log.step("  ", "LLM Translation", f"'{english_query}'")
        
        # Calculate translation time (only for Sinhala queries)
        t_translation_end = time.time()
        translation_time = t_translation_end - t_translation_start if target_lang == 'si' else 0
        if target_lang == 'si':
            Log.step("â±ï¸", "Translation Time", f"{translation_time:.2f}s ({translation_method})")

        # 3.5 [NEW] CONTEXT REWRITER
        # Rewrite query to be standalone (e.g. "it" -> "kidney disease")
        search_query = english_query
        if chat_history:
             # Log handled inside the method, but we can add a high level step here
             pass
             
        search_query = self.llm.contextualize_query(english_query, chat_history)

        # 4. RAG RETRIEVAL (Use REWRITTEN query)
        Log.step("ðŸ“¡", "RAG: Searching Vector DB", f"Query: '{search_query}'")
        t_retrieval_start = time.time()
        search_results = self.vector_db.query_with_nlu(search_query) # <--- Use Search Query
        t_retrieval_end = time.time()
        
        if search_results and 'results' in search_results:
             count = len(search_results['results'])
             Log.step("ðŸ“¥", "DB Retrieval", f"Found {count} candidates")
             for idx, res in enumerate(search_results['results']):
                 doc_id = res.get('metadata', {}).get('source', 'Unknown')
                 score = res.get('score', 0)
                 # print(f"      [{idx+1}] {doc_id} (Score: {score:.4f})") 
        else:
             Log.warning("DB Retrieval: No chunks found")
        
        context_documents = []
        source_metadata = []
        if search_results and 'results' in search_results:
            for item in search_results['results']:
                if item.get('document'):
                    context_documents.append(item['document'])
                if item.get('metadata'):
                    source_metadata.append(item['metadata'])
        
        # 5. RETRIEVE PATIENT DATA (WITH NEW LOGS)
        # -----------------------------------------------------------------
        patient_context = self.patient_data.get_patient_context_string(patient_id)
        Log.step("ðŸ‘¤", "Patient Data", f"Loaded record for '{patient_id}'")
        # -----------------------------------------------------------------

        # 6. GENERATE RESPONSE (Brain Layer)
        Log.step("ðŸ§ ", "BRAIN: Reasoning...")
        t_llm_start = time.time()
        
        llm_response = self.llm.generate_response(
            query=english_query, 
            context_documents=context_documents,
            patient_context=patient_context,
            history=chat_history 
        )
        t_llm_end = time.time()
        Log.step("  ", "Generated Response", f"({t_llm_end - t_llm_start:.2f}s) {llm_response[:50]}...")

        # 6. STYLE LAYER (Translation Back)
        final_response = llm_response
        
        if target_lang == 'si':
            Log.step("ðŸŽ¨", "STYLE: Sinhala Localization...")
            final_response = self.llm.translate_to_sinhala_fallback(llm_response)
            Log.success(f"Final Output: {final_response[:50]}...")
        else:
            Log.step("â„¹ï¸", "STYLE: Skipped (English Mode)")
        
        response_payload = {
            "response": final_response,
            "source_documents": context_documents[:3],
            "source_metadata": source_metadata[:3],
            "nlu_analysis": search_results.get("nlu_analysis", {}),
            "target_lang": target_lang,
            # NEW: Hybrid Smart Route metrics (for thesis/evaluation)
            "translation_method": translation_method if target_lang == 'si' else "none",
            "translation_time": translation_time if target_lang == 'si' else 0
        }
        
        self.cache[cache_key] = response_payload
        
        return response_payload

if __name__ == "__main__":
    rag = RAGEngine()
    
    print("=" * 70)
    print("ðŸ§ª TESTING HYBRID SMART ROUTE + MEDDICT INTEGRATION")
    print("=" * 70)
    
    # Test 1: English (no translation needed)
    print("\n--- Test 1 (English) - No Translation ---")
    result1 = rag.process_query("I want to know about kidney pain")
    print(f"Translation Method: {result1.get('translation_method', 'none')}")
    
    # Test 2: Singlish with clear intent (should use FAST PATH: NLU + MedDict)
    print("\n--- Test 2 (Singlish) - Expected: FAST PATH (NLU + MedDict) ---")
    result2 = rag.process_query("Mata kesel kanna puluwanda?")
    print(f"Translation Method: {result2.get('translation_method')}")
    print(f"Translation Time: {result2.get('translation_time', 0):.3f}s")
    
    # Test 3: Complex Singlish (might use SMART PATH: LLM fallback)
    print("\n--- Test 3 (Complex Singlish) - May use SMART PATH (LLM) ---")
    result3 = rag.process_query("Mage creatinine wadi wela, mokada karanne?")
    print(f"Translation Method: {result3.get('translation_method')}")
    print(f"Translation Time: {result3.get('translation_time', 0):.3f}s")
    
    # Test 4: Pure Sinhala Unicode
    print("\n--- Test 4 (Pure Sinhala) - Testing Unicode handling ---")
    result4 = rag.process_query("à¶¸à¶§ à¶šà·™à·ƒà¶½à·Š à¶šà¶±à·Šà¶± à¶´à·”à·…à·”à·€à¶±à·Šà¶¯?")
    print(f"Translation Method: {result4.get('translation_method')}")
    print(f"Translation Time: {result4.get('translation_time', 0):.3f}s")
    
    print("\n" + "=" * 70)
    print("âœ… HYBRID SMART ROUTE TEST COMPLETE")
    print("=" * 70)